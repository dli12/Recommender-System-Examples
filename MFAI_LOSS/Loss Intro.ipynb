{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn((3, 2), requires_grad=True)\n",
    "target = torch.rand((3, 2), requires_grad=False)\n",
    "loss = F.binary_cross_entropy(torch.sigmoid(input), target)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function binary_cross_entropy in module torch.nn.functional:\n",
      "\n",
      "binary_cross_entropy(input, target, weight=None, size_average=None, reduce=None, reduction='mean')\n",
      "    Function that measures the Binary Cross Entropy\n",
      "    between the target and the output.\n",
      "    \n",
      "    See :class:`~torch.nn.BCELoss` for details.\n",
      "    \n",
      "    Args:\n",
      "        input: Tensor of arbitrary shape\n",
      "        target: Tensor of the same shape as input\n",
      "        weight (Tensor, optional): a manual rescaling weight\n",
      "                if provided it's repeated to match input tensor shape\n",
      "        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "            the losses are averaged over each loss element in the batch. Note that for\n",
      "            some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
      "            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "            when reduce is ``False``. Default: ``True``\n",
      "        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "            losses are averaged or summed over observations for each minibatch depending\n",
      "            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "            ``'mean'``: the sum of the output will be divided by the number of\n",
      "            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "    \n",
      "    Examples::\n",
      "    \n",
      "        >>> input = torch.randn((3, 2), requires_grad=True)\n",
      "        >>> target = torch.rand((3, 2), requires_grad=False)\n",
      "        >>> loss = F.binary_cross_entropy(F.sigmoid(input), target)\n",
      "        >>> loss.backward()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(F.binary_cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9646, grad_fn=<BinaryCrossEntropyBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.4344,  0.3449, -1.5794],\n",
       "         [-0.4576,  0.8981,  0.9115]], requires_grad=True),\n",
       " tensor([[-0.7412, -0.1027,  0.8765],\n",
       "         [ 0.4067, -0.2524,  0.8686]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = torch.randn(2, 3, requires_grad=True)\n",
    "\n",
    "y = torch.randn(2, 3)\n",
    "\n",
    "y_pred, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.1368, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(y_pred - y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0228, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(y_pred - y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = loss(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0228, grad_fn=<L1LossBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
